{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 Managed Services"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2 Cloud Functions (GCP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Echo Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flask"
     ]
    }
   ],
   "source": [
    "!cat scripts/gcp_cloud_function/echo/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def echo(request):\n",
      "    import flask\n",
      "\n",
      "    data = {\"success\": False}\n",
      "    params = request.get_json()\n",
      "\n",
      "    if \"msg\" in params:\n",
      "        data[\"response\"] = str(params['msg'])\n",
      "        data[\"success\"] = True\n",
      "    \n",
      "    return flask.jsonify(data)"
     ]
    }
   ],
   "source": [
    "!cat scripts/gcp_cloud_function/echo/main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_ECHO_SERVICE = \"https://us-central1-semiotic-method-277520.cloudfunctions.net/echo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'Hello from Cloud Function', 'success': True}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "result = requests.post(\n",
    "    url=URL_ECHO_SERVICE, \n",
    "    json={'msg': 'Hello from Cloud Function'}\n",
    ")\n",
    "print(result.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cloud Storage (GCS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dsp_model_store_00\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import storage\n",
    "bucket_name = \"dsp_model_store_00\"\n",
    "\n",
    "storage_client = storage.Client()\n",
    "storage_client.create_bucket(bucket_name)\n",
    "\n",
    "for bucket in storage_client.list_buckets():\n",
    "    print(bucket.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to GCS\n",
    "from google.cloud import storage\n",
    "\n",
    "bucket_name = \"dsp_model_store_00\"\n",
    "storage_client = storage.Client()\n",
    "bucket = storage_client.get_bucket(bucket_name)\n",
    "\n",
    "blob = bucket.blob(\"serverless/logit/v1\")\n",
    "blob.upload_from_filename(\"logit.pkl\")\n",
    "\n",
    "blob = bucket.blob(\"serverless/keras/v1\")\n",
    "blob.upload_from_filename(\"games.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load from GCS\n",
    "import joblib\n",
    "from google.cloud import storage\n",
    "\n",
    "bucket_name = \"dsp_model_store_00\"\n",
    "storage_client = storage.Client()\n",
    "bucket = storage_client.get_bucket(bucket_name)\n",
    "\n",
    "blob = bucket.blob(\"serverless/logit/v1\")\n",
    "blob.download_to_filename(\"/tmp/local_logit.pkl\")\n",
    "\n",
    "model = joblib.load(\"/tmp/local_logit.pkl\")\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "google-cloud-storage\n",
      "sklearn\n",
      "pandas\n",
      "flask\n",
      "joblib"
     ]
    }
   ],
   "source": [
    "!cat scripts/gcp_cloud_function/pred/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def pred(request):\n",
      "\n",
      "    import flask\n",
      "    import joblib\n",
      "    import sklearn\n",
      "    import pandas as pd\n",
      "    from google.cloud import storage\n",
      "\n",
      "    data = {\"success\": False}\n",
      "    params = request.get_json()\n",
      "    \n",
      "    if \"G1\" in params:\n",
      "        new_row = {\"G1\": params.get(\"G1\"), \"G2\": params.get(\"G2\"),\n",
      "                   \"G3\": params.get(\"G3\"), \"G4\": params.get(\"G4\"),\n",
      "                   \"G5\": params.get(\"G5\"), \"G6\": params.get(\"G6\"),\n",
      "                   \"G7\": params.get(\"G7\"), \"G8\": params.get(\"G8\"),\n",
      "                   \"G9\": params.get(\"G9\"), \"G10\":params.get(\"G10\")}\n",
      "        \n",
      "        new_x = pd.DataFrame.from_dict(data=new_row, \n",
      "                                       orient=\"index\",\n",
      "                                       dtype=\"float\").T\n",
      "\n",
      "        # set up access to the GCS bucket\n",
      "        bucket_name = \"dsp_model_store_00\"\n",
      "        storage_client = storage.Client()\n",
      "        bucket = storage_client.get_bucket(bucket_name)\n",
      "\n",
      "        # download and load the model\n",
      "        blob = bucket.blob(\"serverless/logit/v1\")\n",
      "        blob.download_to_filename(\"/tmp/local_logit.pkl\")\n",
      "        model = joblib.load(\"/tmp/local_logit.pkl\")\n",
      "\n",
      "        data[\"response\"] = str(model.predict_proba(new_x)[0][1])\n",
      "        data[\"success\"] = True\n",
      "        \n",
      "    return flask.jsonify(data)"
     ]
    }
   ],
   "source": [
    "!cat scripts/gcp_cloud_function/pred/main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_PRED_SERVICE = \"https://us-central1-semiotic-method-277520.cloudfunctions.net/pred\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': '0.06730006696024816', 'success': True}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "result = requests.post(\n",
    "    url=URL_PRED_SERVICE,\n",
    "    json={'G1': '1', 'G2': '0', 'G3': '0', 'G4': '0', 'G5': '0',\n",
    "          'G6': '0', 'G7': '0', 'G8': '0', 'G9': '0', 'G10': '0'})\n",
    "print(result.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "337 ms ± 28.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "result = requests.post(\n",
    "    url=URL_PRED_SERVICE,\n",
    "    json={'G1': '1', 'G2': '0', 'G3': '0', 'G4': '0', 'G5': '0',\n",
    "          'G6': '0', 'G7': '0', 'G8': '0', 'G9': '0', 'G10': '0'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model = None\n",
      "\n",
      "def pred_fast(request):\n",
      "    global model\n",
      "\n",
      "    import flask\n",
      "    import joblib\n",
      "    import sklearn\n",
      "    import pandas as pd\n",
      "    from google.cloud import storage\n",
      "\n",
      "    data = {\"success\": False}\n",
      "    params = request.get_json()\n",
      "    \n",
      "    if \"G1\" in params:\n",
      "        new_row = {\"G1\": params.get(\"G1\"), \"G2\": params.get(\"G2\"),\n",
      "                   \"G3\": params.get(\"G3\"), \"G4\": params.get(\"G4\"),\n",
      "                   \"G5\": params.get(\"G5\"), \"G6\": params.get(\"G6\"),\n",
      "                   \"G7\": params.get(\"G7\"), \"G8\": params.get(\"G8\"),\n",
      "                   \"G9\": params.get(\"G9\"), \"G10\":params.get(\"G10\")}\n",
      "        \n",
      "        new_x = pd.DataFrame.from_dict(data=new_row, \n",
      "                                       orient=\"index\",\n",
      "                                       dtype=\"float\").T\n",
      "\n",
      "        if not model:\n",
      "            # set up access to the GCS bucket\n",
      "            bucket_name = \"dsp_model_store_00\"\n",
      "            storage_client = storage.Client()\n",
      "            bucket = storage_client.get_bucket(bucket_name)\n",
      "\n",
      "            # download and load the model\n",
      "            blob = bucket.blob(\"serverless/logit/v1\")\n",
      "            blob.download_to_filename(\"/tmp/local_logit.pkl\")\n",
      "            model = joblib.load(\"/tmp/local_logit.pkl\")\n",
      "\n",
      "        data[\"response\"] = str(model.predict_proba(new_x)[0][1])\n",
      "        data[\"success\"] = True\n",
      "        \n",
      "    return flask.jsonify(data)"
     ]
    }
   ],
   "source": [
    "!cat scripts/gcp_cloud_function/pred/main_fast.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_PRED_FAST_SERVICE = \"https://us-central1-semiotic-method-277520.cloudfunctions.net/pred_fast\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': '0.06730006696024816', 'success': True}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "result = requests.post(\n",
    "    url=URL_PRED_FAST_SERVICE,\n",
    "    json={'G1': '1', 'G2': '0', 'G3': '0', 'G4': '0', 'G5': '0',\n",
    "          'G6': '0', 'G7': '0', 'G8': '0', 'G9': '0', 'G10': '0'})\n",
    "print(result.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105 ms ± 4.06 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "result = requests.post(\n",
    "    url=URL_PRED_FAST_SERVICE,\n",
    "    json={'G1': '1', 'G2': '0', 'G3': '0', 'G4': '0', 'G5': '0',\n",
    "          'G6': '0', 'G7': '0', 'G8': '0', 'G9': '0', 'G10': '0'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "google-cloud-storage\n",
      "tensorflow-cpu\n",
      "pandas\n",
      "flask"
     ]
    }
   ],
   "source": [
    "!cat scripts/gcp_cloud_function/predict/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model = None\n",
      "\n",
      "def predict(request):\n",
      "    global model\n",
      "\n",
      "    import flask\n",
      "    import pandas as pd\n",
      "    import tensorflow.keras as K\n",
      "    from google.cloud import storage\n",
      "\n",
      "    data = {\"success\": False}\n",
      "    params = request.get_json()\n",
      "    \n",
      "    if \"G1\" in params:\n",
      "        new_row = {\"G1\": params.get(\"G1\"), \"G2\": params.get(\"G2\"),\n",
      "                   \"G3\": params.get(\"G3\"), \"G4\": params.get(\"G4\"),\n",
      "                   \"G5\": params.get(\"G5\"), \"G6\": params.get(\"G6\"),\n",
      "                   \"G7\": params.get(\"G7\"), \"G8\": params.get(\"G8\"),\n",
      "                   \"G9\": params.get(\"G9\"), \"G10\":params.get(\"G10\")}\n",
      "        \n",
      "        new_x = pd.DataFrame.from_dict(data=new_row, \n",
      "                                       orient=\"index\",\n",
      "                                       dtype=\"float\").T\n",
      "\n",
      "        # download model if not cached\n",
      "        if not model:\n",
      "            # set up access to the GCS bucket\n",
      "            bucket_name = \"dsp_model_store_00\"\n",
      "            storage_client = storage.Client()\n",
      "            bucket = storage_client.get_bucket(bucket_name)\n",
      "\n",
      "            # download and load the model\n",
      "            blob = bucket.blob(\"serverless/keras/v1\")\n",
      "            blob.download_to_filename(\"/tmp/games.h5\")\n",
      "            model = K.models.load_model(\"/tmp/games.h5\")\n",
      "\n",
      "        data[\"response\"] = str(model.predict(new_x)[0][0])\n",
      "        data[\"success\"] = True\n",
      "        \n",
      "    return flask.jsonify(data)"
     ]
    }
   ],
   "source": [
    "!cat scripts/gcp_cloud_function/predict/main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_PREDICT_SERVICE = \"https://us-central1-semiotic-method-277520.cloudfunctions.net/predict\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': '0.03087676', 'success': True}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "result = requests.post(\n",
    "    url=URL_PREDICT_SERVICE,\n",
    "    json={'G1': '1', 'G2': '0', 'G3': '0', 'G4': '0', 'G5': '0',\n",
    "          'G6': '0', 'G7': '0', 'G8': '0', 'G9': '0', 'G10': '0'})\n",
    "print(result.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3 Lambda Functions (AWS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Echo Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def lambda_handler(event, context):\n",
      "    \n",
      "    return {\n",
      "        'statusCode': 200,\n",
      "        'body': event['msg']\n",
      "    }"
     ]
    }
   ],
   "source": [
    "!cat scripts/aws_lambda_function/echo/lambda_function.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Storage Service (S3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !aws configure\n",
    "# !aws s3 ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import json\n",
      "import joblib\n",
      "import pandas as pd\n",
      "\n",
      "\n",
      "model = joblib.load('logit.pkl')\n",
      "\n",
      "\n",
      "def lambda_handler(event, context):\n",
      "    # read in the request body as the event dict\n",
      "    if \"body\" in event:\n",
      "        event = event[\"body\"]\n",
      "        event = json.loads(event) if event else {}\n",
      "    \n",
      "    if \"G1\" in event:\n",
      "        new_row = {\"G1\": event[\"G1\"], \"G2\": event[\"G2\"],\n",
      "                   \"G3\": event[\"G3\"], \"G4\": event[\"G4\"],\n",
      "                   \"G5\": event[\"G5\"], \"G6\": event[\"G6\"], \n",
      "                   \"G7\": event[\"G7\"], \"G8\": event[\"G8\"], \n",
      "                   \"G9\": event[\"G9\"], \"G10\": event[\"G10\"]}\n",
      "        \n",
      "        new_x = pd.DataFrame.from_dict(data=new_row, \n",
      "                                       orient=\"index\",\n",
      "                                       dtype=\"float\").T\n",
      "        \n",
      "        prediction = str(model.predict_proba(new_x)[0][1])\n",
      "        \n",
      "        return {\"body\": \"Prediction \" + prediction}\n",
      "    \n",
      "    return {\"body\": \"No parameters\"}"
     ]
    }
   ],
   "source": [
    "!cat scripts/aws_lambda_function/logit/logit.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction 0.06730006696024816\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "result = requests.post(\n",
    "    url=\"https://c5flbent7a.execute-api.us-east-2.amazonaws.com/default/logit\",\n",
    "    json={'G1': '1', 'G2': '0', 'G3': '0', 'G4': '0', 'G5': '0',\n",
    "          'G6': '0', 'G7': '0', 'G8': '0', 'G9': '0', 'G10': '0'}\n",
    ")\n",
    "print(result.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import json\n",
      "import pandas as pd\n",
      "import tensorflow.keras as K\n",
      "\n",
      "\n",
      "model = K.models.load_model(\"games.h5\")\n",
      "\n",
      "\n",
      "def lambda_handler(event, context):\n",
      "    # read in the request body as the event dict\n",
      "    if \"body\" in event:\n",
      "        event = event[\"body\"]\n",
      "        event = json.loads(event) if event else {}\n",
      "    \n",
      "    if \"G1\" in event:\n",
      "        new_row = {\"G1\": event[\"G1\"], \"G2\": event[\"G2\"],\n",
      "                   \"G3\": event[\"G3\"], \"G4\": event[\"G4\"],\n",
      "                   \"G5\": event[\"G5\"], \"G6\": event[\"G6\"], \n",
      "                   \"G7\": event[\"G7\"], \"G8\": event[\"G8\"], \n",
      "                   \"G9\": event[\"G9\"], \"G10\": event[\"G10\"]}\n",
      "        \n",
      "        new_x = pd.DataFrame.from_dict(data=new_row, \n",
      "                                       orient=\"index\",\n",
      "                                       dtype=\"float\").T\n",
      "        \n",
      "        prediction = str(model.predict(new_x)[0][0])\n",
      "        \n",
      "        return {\"body\": \"Prediction \" + prediction}\n",
      "    \n",
      "    return {\"body\": \"No parameters\"}"
     ]
    }
   ],
   "source": [
    "!cat scripts/aws_lambda_function/keras/keras.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'body': 'Prediction 0.03087676'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scripts.aws_lambda_function.keras.keras import lambda_handler\n",
    "\n",
    "lambda_handler(\n",
    "    event={'G1': '1', 'G2': '0', 'G3': '0', 'G4': '0', 'G5': '0',\n",
    "           'G6': '0', 'G7': '0', 'G8': '0', 'G9': '0', 'G10': '0'},\n",
    "    context=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, <i>\"unzipped size must be smaller than 262144000 bytes\"</i> in order to be deployed as Lambda function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
